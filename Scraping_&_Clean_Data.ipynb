{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tdWhOt575vG"
      },
      "source": [
        "# Main Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF_ENh3atCvf"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye-vuwqI0Sok",
        "outputId": "cb4370f1-c320-42b6-b229-b3e2ce0b86fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=7735bf39e72c7dff4b349500df5dfb1515a9f6caf9372b4d44c8dc1bc8d85349\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3JYDedSB02s"
      },
      "outputs": [],
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "from google.colab import files, drive\n",
        "import getpass\n",
        "import re\n",
        "from langdetect import detect, DetectorFactory, LangDetectException\n",
        "import glob\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksqHGmg9mxlw",
        "outputId": "512a75be-b176-4de5-b687-b2f35c7cead6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tag import pos_tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ-LTgQatXIi"
      },
      "source": [
        "## Extract Comments with Youtube API v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shzPziGAsy_l",
        "outputId": "82ce83fd-bdc3-4938-835d-c4cf6a03197d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your YouTube API key: ··········\n"
          ]
        }
      ],
      "source": [
        "api_key = getpass.getpass('Please enter your YouTube API key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0j6pqh5OZQx"
      },
      "outputs": [],
      "source": [
        "video_ids = ['SdLShOCvVeM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK5fMz-Zgg_F"
      },
      "outputs": [],
      "source": [
        "# Build the YouTube client\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "vUdZCrxHmnL8",
        "outputId": "67e0463e-9084-4b81-f8fe-85c6a1b4e371"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"quotaExceeded\"\n"
          ]
        },
        {
          "ename": "HttpError",
          "evalue": "<HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/comments?part=snippet&parentId=UgzreR97jUZ9CqVZJ2J4AaABAg&textFormat=plainText&maxResults=100&key=AIzaSyAn2QwICy55XHedMrda1Tj6qq8UPcUCgJI&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-f92f85e31e9f>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mvideo_comments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_comments_for_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mall_comments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_comments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-f92f85e31e9f>\u001b[0m in \u001b[0;36mget_comments_for_video\u001b[0;34m(youtube, video_id)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Fetch replies if there are any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'snippet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'totalReplyCount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mall_comments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_replies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'snippet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topLevelComment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mnext_page_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nextPageToken'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-f92f85e31e9f>\u001b[0m in \u001b[0;36mget_replies\u001b[0;34m(youtube, parent_id, video_id)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mpageToken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_page_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         )\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mreply_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreply_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 403 when requesting https://youtube.googleapis.com/youtube/v3/comments?part=snippet&parentId=UgzreR97jUZ9CqVZJ2J4AaABAg&textFormat=plainText&maxResults=100&key=AIzaSyAn2QwICy55XHedMrda1Tj6qq8UPcUCgJI&alt=json returned \"The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.\". Details: \"[{'message': 'The request cannot be completed because you have exceeded your <a href=\"/youtube/v3/getting-started#quota\">quota</a>.', 'domain': 'youtube.quota', 'reason': 'quotaExceeded'}]\">"
          ]
        }
      ],
      "source": [
        "# Function to get replies for a specific comment\n",
        "def get_replies(youtube, parent_id, video_id):  # Added video_id as an argument\n",
        "    replies = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        reply_request = youtube.comments().list(\n",
        "            part=\"snippet\",\n",
        "            parentId=parent_id,\n",
        "            textFormat=\"plainText\",\n",
        "            maxResults=100,\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        reply_response = reply_request.execute()\n",
        "\n",
        "        for item in reply_response['items']:\n",
        "            comment = item['snippet']\n",
        "            replies.append({\n",
        "                'Username': comment['authorDisplayName'],\n",
        "                'VideoID': video_id,\n",
        "                'Comment': comment['textDisplay']\n",
        "            })\n",
        "\n",
        "        next_page_token = reply_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return replies\n",
        "\n",
        "# Function to get all comments (including replies) for a single video\n",
        "def get_comments_for_video(youtube, video_id):\n",
        "    all_comments = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        comment_request = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            pageToken=next_page_token,\n",
        "            textFormat=\"plainText\",\n",
        "            maxResults=100\n",
        "        )\n",
        "        comment_response = comment_request.execute()\n",
        "\n",
        "        for item in comment_response['items']:\n",
        "            top_comment = item['snippet']['topLevelComment']['snippet']\n",
        "            all_comments.append({\n",
        "                'Username': top_comment['authorDisplayName'],\n",
        "                'VideoID': video_id,  # Directly using video_id from function parameter\n",
        "                'Comment': top_comment['textDisplay']\n",
        "            })\n",
        "\n",
        "            # Fetch replies if there are any\n",
        "            if item['snippet']['totalReplyCount'] > 0:\n",
        "                all_comments.extend(get_replies(youtube, item['snippet']['topLevelComment']['id'], video_id))\n",
        "\n",
        "        next_page_token = comment_response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return all_comments\n",
        "\n",
        "# List to hold all comments from all videos\n",
        "all_comments = []\n",
        "\n",
        "\n",
        "for video_id in video_ids:\n",
        "    video_comments = get_comments_for_video(youtube, video_id)\n",
        "    all_comments.extend(video_comments)\n",
        "\n",
        "# Create DataFrame\n",
        "comments_df = pd.DataFrame(all_comments)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQeo2iTwDROo"
      },
      "source": [
        "## Raw Data to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "lJwLzXPiKrtt",
        "outputId": "9eb33b07-d02c-4a34-b2fc-1ef54cd29d4c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-phDM_447hTR"
      },
      "outputs": [],
      "source": [
        "# Export whole dataset to the local machine as CSV File\n",
        "file_path = '/content/drive/MyDrive/skripsi_data/Moto G Play - MKBHD.csv'\n",
        "comments_df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GmzTjetm8Cm"
      },
      "source": [
        "## (1) Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J08EfwcLiXX8"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/skripsi_data/Infinix Note 30 - Gadget Match.csv'\n",
        "comments_df = pd.read_csv(file_path, usecols=['Comment'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiSmdW3Eo6LD",
        "outputId": "186b0989-5030-461a-a7b1-e0c12c300517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             Comment\n",
            "0  Check out the Infinix Note 30 series:\\nNOTE 30...\n",
            "1                                                 😊😅\n",
            "2                                                  P\n",
            "3                             ​@@rotonkhan10030:16 ⁰\n",
            "4                                               Lu 🥀\n"
          ]
        }
      ],
      "source": [
        "print(comments_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_irQZ-27aYdB"
      },
      "outputs": [],
      "source": [
        "def remove_emojis(text):\n",
        "    # Unicode ranges that include most letters and common punctuation\n",
        "    reg = re.compile('[^\\u0000-\\u007F\\u0080-\\u00FF\\u0100-\\u017F\\u0180-\\u024F\\u1E00-\\u1EFF\\u2010-\\u203F]+', re.UNICODE)\n",
        "    return reg.sub('', text)\n",
        "\n",
        "def remove_timestamps(text):\n",
        "    return re.sub(r'\\b\\d{1,2}:\\d{2}\\b', '', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY4nJC8xZYCm"
      },
      "outputs": [],
      "source": [
        "# Define initial set of feature-related keywords\n",
        "base_keywords = ['battery', 'display', 'camera', 'storage',\n",
        "                 'user interface', 'performance', 'price', 'weight',\n",
        "                 'sound', 'durability']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9V3S4hnSasl",
        "outputId": "f905ea8e-adb2-4b57-b549-85e5b2d01c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'just', 'here', 'in', 'whom', 'this', 'we', 'i', 'your', 'same', 'at', 'ours', 'which', 'other', 'will', 'our', 'then', 'are', 'had', 'while', 'ourselves', 'herself', 'between', \"you're\", 'having', 'or', 'itself', 'these', \"it's\", 'has', 'now', 'where', 'all', 'yourself', 'm', 'each', 'myself', 'hers', 'his', 'off', 'to', 'be', 'before', 'themselves', 'her', 'an', 'what', 'yourselves', \"she's\", 'yours', 'during', 'who', 'theirs', 'of', 'once', \"you'd\", 'if', 'on', 'did', 'there', 'few', 'with', 'as', \"that'll\", 'because', 'about', 'for', 'than', 'were', 'and', 'them', 'being', 'my', \"you've\", 'do', 'a', 'll', 'but', 'been', 't', 'is', 'am', 's', 'him', 'its', 'how', 'until', 'you', 'own', 'the', 'that', 'any', 'only', 'after', 'he', 'by', 'd', 'himself', 'again', 'through', 'they', 'such', 'when', 'doing', 'does', 'so', 'she', \"you'll\", 've', 'both', 're', 'have', 'some', 'into', 'it', 'their', 'was', 'o', 'from', 'under', 'me', 'those', 'why', 'y'}\n"
          ]
        }
      ],
      "source": [
        "# Set of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords which affect comments (negation or intensify)\n",
        "stopwords_to_keep = {'can', 'against', 'up', 'down', 'very', 'out', 'over', 'further',\n",
        "                     'above', 'below', 'more', 'most', 'no', 'nor', 'not', 'too', 'very',\n",
        "                     'don', \"don't\", 'should', \"should've\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\",\n",
        "                     'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
        "                     \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\",\n",
        "                     'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"}\n",
        "\n",
        "stop_words = stop_words.difference(stopwords_to_keep)\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym5XtWJf1v1S"
      },
      "outputs": [],
      "source": [
        "# To check is english comment or not\n",
        "DetectorFactory.seed = 0\n",
        "def is_english_comment(comment):\n",
        "    try:\n",
        "        # Detect the language of the comment\n",
        "        return detect(comment) == 'en'\n",
        "    except LangDetectException:\n",
        "        # Handle exception that occurs if the detection fails or text is too short\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnV-vli4rFyJ"
      },
      "outputs": [],
      "source": [
        "def remove_objective_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    subjective_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(words)\n",
        "        objective = False\n",
        "        for word, tag in pos_tags:\n",
        "            if tag in ['WRB', 'WP', 'WP$', 'WDT']:  # Relative pronouns and Wh-words\n",
        "                objective = True\n",
        "                break\n",
        "        if not objective:\n",
        "            subjective_sentences.append(sentence)\n",
        "    return ' '.join(subjective_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwjFrXtYHRy3",
        "outputId": "b0006a0c-fd8a-4e25-86c1-8a63a7499226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seems I won't use it\n"
          ]
        }
      ],
      "source": [
        "test = \"I don't think so how can I enable this feature? Seems I won't use it\"\n",
        "print(remove_objective_sentences(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQjtyc3ra3DI"
      },
      "source": [
        "### Preprocess with Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ4Xnm7KnFNH"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess and filter out irrelevant phrases\n",
        "def preprocess(comments):\n",
        "    preprocessed = []\n",
        "    for comment in comments['Comment']:\n",
        "        comment = str(comment)\n",
        "        if not is_english_comment(comment):\n",
        "            continue  # Skip non-English comments\n",
        "        comment = comment.lower()  # Convert to lower case\n",
        "        comment = remove_emojis(comment)  # Remove emojis\n",
        "        comment = remove_timestamps(comment)  # Remove timestamps\n",
        "        comment = remove_objective_sentences(comment) # Remove questions\n",
        "        if not comment.strip():  # Check if the comment is empty or contains only whitespace\n",
        "            continue  # Skip the comment if it is empty or null\n",
        "        sentences = comment.split('.') # Manually split the comment into sentences on periods\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()  # Remove any leading/trailing whitespace\n",
        "            words = sentence.split()  # Split sentence into words\n",
        "            filtered_words = [word for word in words if '@' not in word]  # Remove '@'\n",
        "            if filtered_words:  # Check if there are any words left after filtering\n",
        "                preprocessed.append(' '.join(filtered_words))  # Join words to form the filtered sentence\n",
        "    return preprocessed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIAYiC5QgG-B"
      },
      "source": [
        "### Preprocess with no Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVZkAQUQfOTx"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess, manually split into sentences on periods, and filter out irrelevant phrases\n",
        "def preprocess_no_stop(comments, stop_words):\n",
        "    preprocessed = []\n",
        "    for comment in comments['Comment']:\n",
        "        comment = str(comment)\n",
        "        if not is_english_comment(comment):\n",
        "            continue  # Skip non-English comments\n",
        "        comment = comment.lower()  # Convert to lower case\n",
        "        comment = remove_emojis(comment)  # Remove emojis\n",
        "        comment = remove_timestamps(comment)  # Remove timestamps\n",
        "        comment = remove_objective_sentences(comment) # Remove questions\n",
        "        if not comment.strip():  # Check if the comment is empty or contains only whitespace\n",
        "            continue  # Skip the comment if it is empty or null\n",
        "        sentences = comment.split('.') # Manually split the comment into sentences on periods\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()  # Remove any leading/trailing whitespace\n",
        "            words = sentence.split() # Split sentence into words\n",
        "            filtered_words = [word for word in words if word not in stop_words and '@' not in word]  # Remove stopwords and '@'\n",
        "            if filtered_words:  # Check if there are any words left after filtering\n",
        "                preprocessed.append(' '.join(filtered_words))  # Join words to form the filtered sentence\n",
        "    return preprocessed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH8rwYVGnZIq"
      },
      "source": [
        "## (2) Feature Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar-FHuDp4wU-"
      },
      "source": [
        "### Keyword Expand with Wordnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kpg0gVNA0lZO"
      },
      "outputs": [],
      "source": [
        "# Expand the Keyword with Wordnet\n",
        "def expand_keywords(base_keywords):\n",
        "    expanded_keywords = {}\n",
        "    reverse_mapping = {}\n",
        "\n",
        "    for keyword in base_keywords:\n",
        "        synonyms = set()\n",
        "        for synset in wn.synsets(keyword):\n",
        "            for lemma in synset.lemmas():\n",
        "                synonym = lemma.name().replace('_', ' ').lower()\n",
        "                synonyms.add(synonym)\n",
        "                reverse_mapping[synonym] = keyword  # Map synonym back to the base keyword\n",
        "        expanded_keywords[keyword] = synonyms\n",
        "\n",
        "    return expanded_keywords, reverse_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkpBaAaI0nYs"
      },
      "outputs": [],
      "source": [
        "# Expand keywords and get reverse mapping\n",
        "expanded_keywords, reverse_mapping = expand_keywords(base_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbcEoCbm0oW5",
        "outputId": "91ee3cfb-7fd2-4340-95b1-2b5b149b8064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'battery': {'barrage', 'stamp battery', 'bombardment', 'assault and battery', 'barrage fire', 'shelling', 'battery', 'electric battery'}, 'display': {'exhibit', 'display', 'show', 'expose', 'video display', 'presentation', 'showing'}, 'camera': {'tv camera', 'television camera', 'photographic camera', 'camera'}, 'storage': {'warehousing', 'entrepot', 'storage', 'storehouse', 'computer memory', 'repositing', 'store', 'reposition', 'memory board', 'computer storage', 'memory', 'depot'}, 'user interface': set(), 'performance': {'execution', 'public presentation', 'carrying into action', 'carrying out', 'functioning', 'operation', 'performance'}, 'price': {'price', 'terms', 'mary leontyne price', 'damage', 'monetary value', 'cost', 'toll', 'leontyne price'}, 'weight': {'exercising weight', 'angle', 'weight down', 'system of weights', 'weight', 'weight unit', 'burden', 'burthen', 'slant', 'free weight', 'weightiness', 'weighting'}, 'sound': {'healthy', 'level-headed', 'speech sound', 'profound', 'phone', 'effectual', 'sound', 'heavy', 'vocalize', 'vocalise', 'wakeless', 'audio', 'strait', 'good', 'auditory sensation', 'reasoned', 'go', 'legal', 'intelligent', 'levelheaded', 'fathom', 'voice', 'well-grounded'}, 'durability': {'lastingness', 'enduringness', 'strength', 'durability'}}\n"
          ]
        }
      ],
      "source": [
        "print(expanded_keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuvlaRpT00Dc",
        "outputId": "27e9a8f8-1cfc-4107-97a5-dda2f2186ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'battery': 'battery', 'electric battery': 'battery', 'stamp battery': 'battery', 'barrage': 'battery', 'barrage fire': 'battery', 'bombardment': 'battery', 'shelling': 'battery', 'assault and battery': 'battery', 'display': 'display', 'show': 'display', 'exhibit': 'display', 'showing': 'display', 'presentation': 'display', 'video display': 'display', 'expose': 'display', 'camera': 'camera', 'photographic camera': 'camera', 'television camera': 'camera', 'tv camera': 'camera', 'storage': 'storage', 'storehouse': 'storage', 'depot': 'storage', 'entrepot': 'storage', 'store': 'storage', 'memory': 'storage', 'computer memory': 'storage', 'computer storage': 'storage', 'memory board': 'storage', 'repositing': 'storage', 'reposition': 'storage', 'warehousing': 'storage', 'performance': 'performance', 'public presentation': 'performance', 'execution': 'performance', 'carrying out': 'performance', 'carrying into action': 'performance', 'operation': 'performance', 'functioning': 'performance', 'monetary value': 'price', 'price': 'price', 'cost': 'price', 'terms': 'price', 'damage': 'price', 'toll': 'price', 'leontyne price': 'price', 'mary leontyne price': 'price', 'weight': 'weight', 'free weight': 'weight', 'exercising weight': 'weight', 'weightiness': 'weight', 'system of weights': 'weight', 'weight unit': 'weight', 'weighting': 'weight', 'burden': 'weight', 'burthen': 'weight', 'weight down': 'weight', 'slant': 'weight', 'angle': 'weight', 'sound': 'sound', 'auditory sensation': 'sound', 'audio': 'sound', 'phone': 'sound', 'speech sound': 'sound', 'strait': 'sound', 'go': 'sound', 'voice': 'sound', 'vocalize': 'sound', 'vocalise': 'sound', 'fathom': 'sound', 'healthy': 'sound', 'intelligent': 'sound', 'levelheaded': 'sound', 'level-headed': 'sound', 'good': 'sound', 'reasoned': 'sound', 'well-grounded': 'sound', 'legal': 'sound', 'effectual': 'sound', 'heavy': 'sound', 'profound': 'sound', 'wakeless': 'sound', 'lastingness': 'durability', 'durability': 'durability', 'enduringness': 'durability', 'strength': 'durability'}\n"
          ]
        }
      ],
      "source": [
        "print(reverse_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BzY5xZu49eJ"
      },
      "source": [
        "### Alter the Expanded Keyword after observing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HfIgTz54sH8"
      },
      "outputs": [],
      "source": [
        "# Dictionary containing the base keyword and the expanded keywords\n",
        "keyword_expansions = {\n",
        "    \"battery\": {\n",
        "        \"battery\", \"stamp battery\", \"long-lasting\", \"long last\", \"long lasting\",\n",
        "        \"long-last\", \"lasts\", \"hold out\", \"holds out\", \"mark\", \"charge\", \"charging\", \"mah\",\n",
        "        \"life\"\n",
        "    },\n",
        "    \"display\": {\n",
        "        \"display\", \"displays\", \"resolution\", \"aspect ratio\", \"res\", \"inch\", \"inches\",\n",
        "        \"screen\", \"dimension\", \"pixel\", \"panel\", \"panels\", \"bright\", \"brightness\",\n",
        "        \"contrast\", \"contrasts\", \"visibility\", \"visible\", \"rgb\", \"refresh rate\",\n",
        "        \"warm\", \"color\", \"colour\", \"hz\"\n",
        "    },\n",
        "    \"camera\": {\n",
        "        \"camera\", \"picture\", \"video\", \"videos\", \"images\", \"image\", \"photos\", \"photo\",\n",
        "        \"photography\", \"lense\", \"lenses\", \"rear\", \"front\", \"zoom\", \"shoot\", \"shoots\",\n",
        "        \"shot\", \"shots\", \"shooting\", \"blur\", \"blurry\", \"blurs\", \"record\", \"recording\", \"records\"\n",
        "    },\n",
        "    \"storage\": {\n",
        "        \"stores\", \"store\", \"gb\", \"tb\", \"storage\", \"memory\", \"expandable\"\n",
        "    },\n",
        "    \"performance\": {\n",
        "        \"functioning\", \"operation\", \"performance\", \"perform\", \"performs\", \"ram\",\n",
        "        \"cpu\", \"chipset\", \"chip\", \"chips\", \"lag\", \"lags\", \"processor\", \"procie\", \"lagging\",\n",
        "        \"stuttering\", \"stutter\", \"stutters\", \"spikes\", \"spike\", \"freeze\", \"fps\", \"stable\", \"unstable\"\n",
        "    },\n",
        "    \"price\": {\n",
        "        \"value\", \"values\", \"expensive\", \"cheap\", \"cost\", \"costs\", \"toll\", \"price\",\n",
        "        \"prices\", \"inexpensive\", \"money\"\n",
        "    },\n",
        "    \"weight\": {\n",
        "        \"burden\", \"weighting\", \"weightiness\", \"burthen\", \"weight\", \"weights\", \"heavy\", \"heavier\", \"heaviest\", \"light\",\n",
        "        \"lightweight\", \"lighter\", \"lightest\"\n",
        "    },\n",
        "    \"sound\": {\n",
        "        \"noise\", \"noises\", \"clear\", \"voice\", \"audio\", \"sound\", \"sounds\", \"speaker\",\n",
        "        \"speech sound\", \"well-grounded\", \"profound\", \"vocalise\", \"vocalize\", \"level-headed\",\n",
        "        \"auditory sensation\"\n",
        "    },\n",
        "    \"durability\": {\n",
        "        \"durability\", \"durable\", \"build\", \"material\", \"waterproof\", \"proof\", \"resistant\",\n",
        "        \"rugged\", \"robust\", \"fell\", \"falls\", \"fall\", \"break\", \"breaks\", \"broken\", \"broke\"\n",
        "    },\n",
        "    \"user interface\": {\n",
        "        \"minimalistic\", \"ui\", \"user interface\", \"clean\", \"skins\", \"skin\", \"icons\", \"icon\", \"interface\"\n",
        "    }\n",
        "}\n",
        "\n",
        "keyword_expansions_1 = {\n",
        "    \"battery\",\n",
        "    \"display\",\n",
        "    \"camera\",\n",
        "    \"storage\",\n",
        "    \"performance\",\n",
        "    \"price\",\n",
        "    \"weight\",\n",
        "    \"sound\",\n",
        "    \"durability\",\n",
        "    \"user interface\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KwPNvO-5Y78"
      },
      "outputs": [],
      "source": [
        "# Creating a reverse mapping dictionary\n",
        "reverse_mapping = {}\n",
        "for base_keyword, expansions in keyword_expansions.items():\n",
        "    for expansion in expansions:\n",
        "        reverse_mapping[expansion] = base_keyword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SLsurN-52O7",
        "outputId": "d050f670-4d27-48a9-98cf-f2109db11116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_items([('mah', 'battery'), ('long-lasting', 'battery'), ('hold out', 'battery'), ('stamp battery', 'battery'), ('lasts', 'battery'), ('long last', 'battery'), ('long lasting', 'battery'), ('holds out', 'battery'), ('mark', 'battery'), ('charge', 'battery'), ('charging', 'battery'), ('battery', 'battery'), ('long-last', 'battery'), ('life', 'battery'), ('color', 'display'), ('display', 'display'), ('bright', 'display'), ('rgb', 'display'), ('hz', 'display'), ('visible', 'display'), ('panel', 'display'), ('contrast', 'display'), ('res', 'display'), ('aspect ratio', 'display'), ('brightness', 'display'), ('inch', 'display'), ('screen', 'display'), ('refresh rate', 'display'), ('visibility', 'display'), ('panels', 'display'), ('inches', 'display'), ('contrasts', 'display'), ('displays', 'display'), ('warm', 'display'), ('colour', 'display'), ('dimension', 'display'), ('resolution', 'display'), ('pixel', 'display'), ('image', 'camera'), ('video', 'camera'), ('lense', 'camera'), ('shots', 'camera'), ('blurry', 'camera'), ('shot', 'camera'), ('photography', 'camera'), ('zoom', 'camera'), ('records', 'camera'), ('camera', 'camera'), ('front', 'camera'), ('recording', 'camera'), ('photo', 'camera'), ('images', 'camera'), ('lenses', 'camera'), ('shoots', 'camera'), ('record', 'camera'), ('photos', 'camera'), ('shoot', 'camera'), ('rear', 'camera'), ('picture', 'camera'), ('shooting', 'camera'), ('blur', 'camera'), ('videos', 'camera'), ('blurs', 'camera'), ('tb', 'storage'), ('storage', 'storage'), ('memory', 'storage'), ('stores', 'storage'), ('store', 'storage'), ('gb', 'storage'), ('expandable', 'storage'), ('chips', 'performance'), ('lagging', 'performance'), ('ram', 'performance'), ('fps', 'performance'), ('perform', 'performance'), ('chip', 'performance'), ('functioning', 'performance'), ('lag', 'performance'), ('stable', 'performance'), ('spikes', 'performance'), ('performs', 'performance'), ('chipset', 'performance'), ('unstable', 'performance'), ('cpu', 'performance'), ('lags', 'performance'), ('stuttering', 'performance'), ('freeze', 'performance'), ('processor', 'performance'), ('procie', 'performance'), ('operation', 'performance'), ('spike', 'performance'), ('performance', 'performance'), ('stutter', 'performance'), ('stutters', 'performance'), ('value', 'price'), ('price', 'price'), ('expensive', 'price'), ('prices', 'price'), ('money', 'price'), ('inexpensive', 'price'), ('cost', 'price'), ('toll', 'price'), ('cheap', 'price'), ('values', 'price'), ('costs', 'price'), ('heavier', 'weight'), ('lightest', 'weight'), ('lightweight', 'weight'), ('heaviest', 'weight'), ('heavy', 'weight'), ('light', 'weight'), ('weight', 'weight'), ('burden', 'weight'), ('burthen', 'weight'), ('weights', 'weight'), ('lighter', 'weight'), ('weightiness', 'weight'), ('weighting', 'weight'), ('noise', 'sound'), ('auditory sensation', 'sound'), ('sound', 'sound'), ('clear', 'sound'), ('level-headed', 'sound'), ('speaker', 'sound'), ('voice', 'sound'), ('speech sound', 'sound'), ('vocalize', 'sound'), ('vocalise', 'sound'), ('well-grounded', 'sound'), ('audio', 'sound'), ('profound', 'sound'), ('noises', 'sound'), ('sounds', 'sound'), ('fall', 'durability'), ('break', 'durability'), ('broken', 'durability'), ('broke', 'durability'), ('build', 'durability'), ('durability', 'durability'), ('fell', 'durability'), ('proof', 'durability'), ('breaks', 'durability'), ('rugged', 'durability'), ('waterproof', 'durability'), ('resistant', 'durability'), ('falls', 'durability'), ('material', 'durability'), ('durable', 'durability'), ('robust', 'durability'), ('user interface', 'user interface'), ('icon', 'user interface'), ('skin', 'user interface'), ('minimalistic', 'user interface'), ('clean', 'user interface'), ('interface', 'user interface'), ('icons', 'user interface'), ('skins', 'user interface'), ('ui', 'user interface')])\n"
          ]
        }
      ],
      "source": [
        "print(reverse_mapping.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEEAvKhA8G7V"
      },
      "source": [
        "### Comment Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t40q1jbonexx"
      },
      "outputs": [],
      "source": [
        "# Function to assign labels based on keywords\n",
        "def label_comments(comments, reverse_mapping):\n",
        "    labeled_comments = []\n",
        "    for comment in comments:\n",
        "        comment_lower = comment.lower()  # Normalize case\n",
        "        labels = set()\n",
        "        # Check for each keyword in the reverse mapping\n",
        "        for keyword, base_keyword in reverse_mapping.items():\n",
        "            # Using regex to match whole words only, considering plural and connected forms\n",
        "            if re.search(r'\\b' + re.escape(keyword) + r'\\b', comment_lower):\n",
        "                labels.add(base_keyword)\n",
        "        # If no specific labels were found, assign 'None'\n",
        "        if not labels:\n",
        "            labels = ['None']\n",
        "        # Create a new entry for each label found\n",
        "        for label in labels:\n",
        "            labeled_comments.append({'Comment': comment, 'Label': label})\n",
        "    return labeled_comments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ7G0rGw8zIn"
      },
      "source": [
        "## (3) Sentiment Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lhOhB2YNemZ"
      },
      "source": [
        "### Scoring Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOKVQrzr86JK"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ek6N1oIb9AdR"
      },
      "outputs": [],
      "source": [
        "# Function to map NLTK position tags to WordNet position tags\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to calculate sentiment score using SentiWordNet\n",
        "def calculate_sentiment_score(text):\n",
        "    sentiment_score = 0\n",
        "    words = word_tokenize(text)\n",
        "    pos_tags = pos_tag(words)\n",
        "\n",
        "    for word, tag in pos_tags:\n",
        "        wn_tag = get_wordnet_pos(tag)\n",
        "        if wn_tag is None:\n",
        "            continue\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "        synsets = wn.synsets(lemma, pos=wn_tag)\n",
        "        if not synsets:\n",
        "            continue\n",
        "        synset = synsets[0]\n",
        "        senti_synset = swn.senti_synset(synset.name())\n",
        "        sentiment_score += senti_synset.pos_score() - senti_synset.neg_score()\n",
        "    return sentiment_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52n5dHg52ZrU",
        "outputId": "da83ce1d-8d4d-4c1e-c36c-e70282187edc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.125\n"
          ]
        }
      ],
      "source": [
        "review = \"it doesnt really seem like its worth it to buy the standard iphone 14/and plus too if you have a iphone 13, and spending your money on a iphone 14 could just be a waste\"\n",
        "print(calculate_sentiment_score(review))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_GlRNZNhj8"
      },
      "source": [
        "## (4) Generate CSV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y2_RNb53Nra"
      },
      "source": [
        "### Pre Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S66BTb69ZmY1"
      },
      "outputs": [],
      "source": [
        "# # Preprocess raw data\n",
        "# preprocessed_comments = preprocess_no_stop(comments_df)\n",
        "\n",
        "# filtered_df = pd.DataFrame(preprocessed_comments, columns=['Relevant Comment'])\n",
        "\n",
        "# output_path = '/content/drive/My Drive/clean_data/Mid Range/Iphone SE 3/1) Preprocessed - MKBHD.csv'\n",
        "# filtered_df.to_csv(output_path, index=False)\n",
        "\n",
        "# Preprocess raw data and remove stop words\n",
        "preprocessed_comments_no_stop = preprocess_no_stop(comments_df, stop_words)\n",
        "\n",
        "filtered_df_no_stop = pd.DataFrame(preprocessed_comments_no_stop, columns=['Relevant Comment'])\n",
        "\n",
        "output_path = '/content/drive/My Drive/clean_data/Low End/Infinix Note 30/1) Preprocessed no Stop - GadgetMatch.csv'\n",
        "filtered_df_no_stop.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjUSOqKo3P4m"
      },
      "source": [
        "### Labeling with no stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ0oSb_PCRCf",
        "outputId": "bd189937-aefc-4c82-d327-b3b8d4c245fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labeled and scored done\n",
            "                                              Comment       Label  \\\n",
            "4                                        great video!      camera   \n",
            "5                     thank much beautiful break down  durability   \n",
            "8   indeed not need lot money, hate comments peopl...       price   \n",
            "10             feels heavy, won't recommend daily use      weight   \n",
            "27        country official store sells 120usd new set     storage   \n",
            "\n",
            "    Sentiment Score  \n",
            "4             0.000  \n",
            "5             0.000  \n",
            "8            -0.625  \n",
            "10            0.000  \n",
            "27            0.500  \n",
            "labeled, scored, filtered done\n"
          ]
        }
      ],
      "source": [
        "# Label the comments\n",
        "labeled_comments = label_comments(preprocessed_comments_no_stop, reverse_mapping)\n",
        "\n",
        "# Add sentiment scores to labeled comments\n",
        "for comment_data in labeled_comments:\n",
        "    comment_text = comment_data['Comment']\n",
        "    sentiment_score = calculate_sentiment_score(comment_text)\n",
        "    comment_data['Sentiment Score'] = sentiment_score\n",
        "\n",
        "# Convert the list of labeled comments to a DataFrame\n",
        "labeled_df = pd.DataFrame(labeled_comments)\n",
        "\n",
        "# Save the labeled comments including 'None' to a CSV file\n",
        "output_path = '/content/drive/My Drive/clean_data/Low End/Infinix Note 30/2) Labeled, Scored, with None and No Stop - GadgetMatch.csv'\n",
        "labeled_df.to_csv(output_path, index=False)\n",
        "print(\"labeled and scored done\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "labeled_df_filtered = labeled_df[labeled_df['Label'] != 'None']\n",
        "print(labeled_df_filtered.head())\n",
        "\n",
        "# Save the DataFrame to CSV\n",
        "output_path_filtered = '/content/drive/My Drive/clean_data/Low End/Infinix Note 30/3) Labeled, Scored, and No Stop - GadgetMatch.csv'\n",
        "labeled_df_filtered.to_csv(output_path_filtered, index=False)\n",
        "print(\"labeled, scored, filtered done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjpw_jT3EXfp"
      },
      "outputs": [],
      "source": [
        "def sum_sentiment_scores(csv_files):\n",
        "    # Initialize dictionaries to hold the sum of sentiment scores and counts for each label\n",
        "    sentiment_sums = {}\n",
        "    comment_counts = {}\n",
        "\n",
        "    # Iterate over each CSV file\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            # Read only the 'Label' and 'Sentiment Score' columns\n",
        "            df = pd.read_csv(file, usecols=['Label', 'Sentiment Score'])\n",
        "            for index, row in df.iterrows():\n",
        "                label = row['Label']\n",
        "                score = row['Sentiment Score']\n",
        "                if label in sentiment_sums:\n",
        "                    sentiment_sums[label] += score\n",
        "                    comment_counts[label] += 1\n",
        "                else:\n",
        "                    sentiment_sums[label] = score\n",
        "                    comment_counts[label] = 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "    return sentiment_sums, comment_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaGJpvg-FKsc"
      },
      "outputs": [],
      "source": [
        "csv_files = [\n",
        "    '/content/drive/MyDrive/clean_data/Low End/Infinix Note 30/3) Labeled, Scored, and No Stop - GadgetMatch.csv',\n",
        "    '/content/drive/MyDrive/clean_data/Low End/Infinix Note 30/3) Labeled, Scored, and No Stop - ValorReviews.csv',\n",
        "    # Add more directories as needed\n",
        "]\n",
        "\n",
        "sentiment_sums, comment_counts = sum_sentiment_scores(csv_files)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Label': list(sentiment_sums.keys()),\n",
        "    'Total Sentiment Score': list(sentiment_sums.values()),\n",
        "    'Comment Count': [comment_counts[label] for label in sentiment_sums.keys()]\n",
        "})\n",
        "\n",
        "results_file_path = '/content/drive/MyDrive/ready_data/Infinix Note 30.csv'\n",
        "results_df.to_csv(results_file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZwvlCYoTEDb"
      },
      "outputs": [],
      "source": [
        "def process_sentiment_scores(directory):\n",
        "    results = []\n",
        "\n",
        "    # Find all CSV files in the directory\n",
        "    csv_files = glob.glob(f'{directory}/*.csv')\n",
        "\n",
        "    # Iterate over each CSV file\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            # Read the 'Label', 'Total Sentiment Score', and 'Comment Count' columns\n",
        "            df = pd.read_csv(file, usecols=['Label', 'Total Sentiment Score', 'Comment Count'])\n",
        "            scores_counts = df.set_index('Label')[['Total Sentiment Score', 'Comment Count']].T.to_dict('list')\n",
        "            file_name = os.path.splitext(os.path.basename(file))[0]  # Get file name without extension\n",
        "            result = {'Phone': file_name}\n",
        "            result.update(scores_counts)\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ilXGyRDTPSv"
      },
      "outputs": [],
      "source": [
        "# Directory containing CSV files in Google Drive\n",
        "directory = '/content/drive/MyDrive/ready_data'\n",
        "\n",
        "# Process sentiment scores from all files in the directory\n",
        "results = process_sentiment_scores(directory)\n",
        "\n",
        "# Convert the results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save the results to Google Drive\n",
        "results_file_path = '/content/drive/My Drive/sentiment_scores_matrix.csv'\n",
        "results_df.to_csv(results_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZibwGRB3Tsn"
      },
      "source": [
        "### Labeling with stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPDUTayKVE30",
        "outputId": "8db33262-f9c5-4400-cad9-ed1b1701fd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labeled and scored done\n",
            "                                              Comment        Label  \\\n",
            "7   a73 for future-proofing s20 fe if you want a j...      display   \n",
            "10  yes i brought it last month as i use to have s...       camera   \n",
            "13  the a73 does 70-80% of the s22 ultra for about...        price   \n",
            "15  all i really wanted as headphone jack, better ...  performance   \n",
            "16  all i really wanted as headphone jack, better ...      storage   \n",
            "\n",
            "    Sentiment Score  \n",
            "7             0.500  \n",
            "10            1.000  \n",
            "13            0.000  \n",
            "15            1.625  \n",
            "16            1.625  \n",
            "labeled, scored, filtered done\n"
          ]
        }
      ],
      "source": [
        "# Label the comments\n",
        "labeled_comments = label_comments(preprocessed_comments, reverse_mapping)\n",
        "\n",
        "# Add sentiment scores to labeled comments\n",
        "for comment_data in labeled_comments:\n",
        "    comment_text = comment_data['Comment']\n",
        "    sentiment_score = calculate_sentiment_score(comment_text)\n",
        "    comment_data['Sentiment Score'] = sentiment_score\n",
        "\n",
        "# Convert the list of labeled comments to a DataFrame\n",
        "labeled_df = pd.DataFrame(labeled_comments)\n",
        "\n",
        "# Save the labeled comments including 'None' to a CSV file\n",
        "output_path = '/content/drive/My Drive/clean_data/Mid Range/Samsung A73/5) Labeled, Scored, & with None - TechDaily.csv'\n",
        "labeled_df.to_csv(output_path, index=False)\n",
        "print(\"labeled and scored done\")\n",
        "\n",
        "# Convert to DataFrame\n",
        "labeled_df_filtered = labeled_df[labeled_df['Label'] != 'None']\n",
        "print(labeled_df_filtered.head())\n",
        "\n",
        "# Save the DataFrame to CSV\n",
        "output_path_filtered = '/content/drive/My Drive/clean_data/Mid Range/Samsung A73/6) Labeled & Scored - TechDaily.csv'\n",
        "labeled_df_filtered.to_csv(output_path_filtered, index=False)\n",
        "print(\"labeled, scored, filtered done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbET0UBbhWPY"
      },
      "source": [
        "# Testing Other Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQWjrr_O8v4y"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D8_LBDWoaXZ",
        "outputId": "93fcbbf7-0da1-4e12-f7c3-ad5fa415c2e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting emoji\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=162288468c5be70cc47a9fc2de6c98bba8e441f8b5fce83eb5f1e78f46b99c67\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect, emoji\n",
            "Successfully installed emoji-2.12.1 langdetect-1.0.9\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n",
            "Collecting stanza\n",
            "  Downloading stanza-1.8.2-py3-none-any.whl (990 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.1/990.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from stanza) (2.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->stanza)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 stanza-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install langdetect textblob emoji\n",
        "!python -m textblob.download_corpora\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtoSqBl1hVxV",
        "outputId": "8e5ed26f-4d51-4241-cbc1-297b86ff76f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.corpus import wordnet as wn\n",
        "import re\n",
        "from langdetect import detect\n",
        "from textblob import TextBlob\n",
        "import emoji\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669,
          "referenced_widgets": [
            "2a051626c39740ec84c46d6162120c9d",
            "0ea0faf00c4f49a18a58909bbde9f033",
            "4f5ce3f29b1a469eae4547fe647c5779",
            "d2b13dc27e7d40cd90098aedf12fb0b5",
            "25c41c90875542e5a371964bc8afb4f1",
            "12c1d9fc7a67443db1363885e59d925b",
            "b849f91d9d114ff0a946835eb65b46bb",
            "6e168bbb9b6e481a8170a5755e620267",
            "c022bef93aa2489babc0b598695cf250",
            "594f1bdecb4b44a2989173808be18edb",
            "6675d1a0e2b641519842de6f0048f7e7",
            "ce925bb0ff354ea49a83977cabc8dad8",
            "1e38d66b65d747b096fc220ed3dc183d",
            "8007b88fb6e04aa5b576bb7708d8f772",
            "fa2d09abd60c45ceadf6b9bfe03f54ee",
            "b7de5ec64d2c4fbabf0a6dfd72374308",
            "18bc662c73cc496d8134115d8c665b40",
            "675579a2a7f84d1c9b50554d80ba9bfd",
            "27380f26e19a4dfc80ef49884ceb6be1",
            "713e87e5fb0647b6b8c3af837200ad68",
            "a6332d64ca7d4ade91b5736a608ad58e",
            "97a3522034d24241aada652f76b64f16",
            "b220ad4c995d4fcab809e7205182741c",
            "d78053a1b9ac4dfc9ced4c1b6534e35b",
            "7780c707c71949b58329d5246e659943",
            "e3ef2d45d8be47dc991df0fd6d46e8ad",
            "fd414f991fca4b8dade68e4cf7bd0873",
            "d7713d5bc17545b5aea811148fcfda08",
            "ef8eb460a4f04ee1b3f9ed14cc32fdcb",
            "cf519aad79e84cb69dd8bd891e9a1dad",
            "1bbde817185649b8bed1ed1b2d06f416",
            "81729b660cc148aea81b5d29a9a15f5a",
            "7d1bd2a1f6894fd2b22873070e2e57a4"
          ]
        },
        "id": "UeSgRvFe4hb6",
        "outputId": "2615e137-bd36-4d1a-f08f-9e5c596237b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a051626c39740ec84c46d6162120c9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: en (English) ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce925bb0ff354ea49a83977cabc8dad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/default.zip:   0%|          | 0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/en/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b220ad4c995d4fcab809e7205182741c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Loading these models for language: en (English):\n",
            "============================================\n",
            "| Processor    | Package                   |\n",
            "--------------------------------------------\n",
            "| tokenize     | combined                  |\n",
            "| mwt          | combined                  |\n",
            "| pos          | combined_charlm           |\n",
            "| lemma        | combined_nocharlm         |\n",
            "| constituency | ptb3-revised_charlm       |\n",
            "| depparse     | combined_charlm           |\n",
            "| sentiment    | sstplus_charlm            |\n",
            "| ner          | ontonotes-ww-multi_charlm |\n",
            "============================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: mwt\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: lemma\n",
            "INFO:stanza:Loading: constituency\n",
            "INFO:stanza:Loading: depparse\n",
            "INFO:stanza:Loading: sentiment\n",
            "INFO:stanza:Loading: ner\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "import stanza\n",
        "stanza.download('en')\n",
        "nlp = stanza.Pipeline('en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FVUM3Z18s77"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HNqE9STogjZ",
        "outputId": "6af27754-cc95-4a87-a2ff-2eeda7bf13fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVXLJPJS80mN"
      },
      "outputs": [],
      "source": [
        "# Function to detect if a text is English\n",
        "def is_english(text):\n",
        "    try:\n",
        "        return detect(text) == 'en'\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "# Function to remove emojis from text\n",
        "def remove_emojis(text):\n",
        "    return emoji.replace_emoji(text, \"\")\n",
        "\n",
        "# Function to remove timestamps in the format xx:xx\n",
        "def remove_timestamps(text):\n",
        "    return re.sub(r'\\b\\d{1,2}:\\d{2}\\b', '', text)\n",
        "\n",
        "# Combined preprocessing function\n",
        "def preprocess_text(text):\n",
        "    if not is_english(text):\n",
        "        return None\n",
        "    text = remove_emojis(text)\n",
        "    text = remove_timestamps(text)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4N6N_hp80x3"
      },
      "source": [
        "## Sentence Level Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xnqn_nl2Oc4"
      },
      "outputs": [],
      "source": [
        "# Function to remove objective sentences\n",
        "def remove_objective_sentences(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    sentences = sent_tokenize(text)\n",
        "    subjective_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(words)\n",
        "        objective = False\n",
        "        for word, tag in pos_tags:\n",
        "            if tag in ['WRB', 'WP', 'WP$', 'WDT']:  # Relative pronouns and Wh-words\n",
        "                objective = True\n",
        "                break\n",
        "        if not objective:\n",
        "            subjective_sentences.append(sentence)\n",
        "    return ' '.join(subjective_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAvyH6Jlv9Ym",
        "outputId": "8dcda220-74f5-4d30-ed52-bd3668edd4a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# text = \"Who else has used this feature?\"\n",
        "# filtered_sentences = remove_objective_sentences(text)\n",
        "# print(filtered_sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tskt3OxT88AO"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeGRqZKk2cJa"
      },
      "outputs": [],
      "source": [
        "# def extract_features(sentences):\n",
        "#     features = []\n",
        "#     for sentence in sentences:\n",
        "#         words = word_tokenize(sentence)\n",
        "#         pos_tags = pos_tag(words)\n",
        "#         for word, tag in pos_tags:\n",
        "#             if tag in ['NN', 'NNS', 'NNP', 'NNPS']:  # Nouns\n",
        "#                 features.append(word)\n",
        "#     return features\n",
        "\n",
        "def extract_features(sentences):\n",
        "    features_dict = {}\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        pos_tags = pos_tag(words)\n",
        "        features = [word for word, tag in pos_tags if tag in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
        "        features_dict[sentence] = features\n",
        "    return features_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k76aZaKA9Cph"
      },
      "source": [
        "## Get Words Dependencies on Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmNl7aRQ2crf"
      },
      "outputs": [],
      "source": [
        "# def extract_opinion_words(sentences, features):\n",
        "#     opinion_words = {}\n",
        "#     for sentence in sentences:\n",
        "#         doc = nlp(sentence)\n",
        "#         # print(\"Parsed : \", doc)\n",
        "#         for sent in doc.sentences:\n",
        "#             for word in sent.words:\n",
        "#                 print(f\"Word: {word.text}, Head: {head.text}, Dependency: {word.deprel}\")\n",
        "#                 if word.deprel in ['amod', 'xcomp', 'advmod', 'nsubj', 'neg']:  # Adjectival modifier, adjectival complement, adverbial modifier\n",
        "#                     head = sent.words[word.head - 1]\n",
        "#                     if head.text in features:\n",
        "#                         if head.text not in opinion_words:\n",
        "#                             opinion_words[head.text] = []\n",
        "#                         opinion_words[head.text].append(word.text)\n",
        "#     return opinion_words\n",
        "\n",
        "# def extract_opinion_words(features_dict):\n",
        "#     opinion_words_list = []\n",
        "#     for sentence, features in features_dict.items():\n",
        "#         opinion_words = {}\n",
        "#         doc = nlp(sentence)\n",
        "#         for sent in doc.sentences:\n",
        "#             print(sent)\n",
        "#             for word in sent.words:\n",
        "#                 if word.deprel in ['amod', 'xcomp', 'advmod', 'nsubj', 'neg']:  # Specified dependencies\n",
        "#                     head = sent.words[word.head - 1]\n",
        "#                     if head.text in features:\n",
        "#                         opinion_words[word.text] = head.text\n",
        "#         opinion_words_list.append(opinion_words)\n",
        "#     return opinion_words_list\n",
        "\n",
        "def extract_opinion_words(features_dict):\n",
        "    opinion_words_list = []\n",
        "    for sentence, features in features_dict.items():\n",
        "        opinion_words = {}\n",
        "        doc = nlp(sentence)\n",
        "        for sent in doc.sentences:\n",
        "            for word in sent.words:\n",
        "                head = sent.words[word.head - 1] if word.head > 0 else None\n",
        "                if word.deprel in ['amod', 'xcomp', 'advmod', 'nsubj', 'neg']:\n",
        "                    if (head and head.text in features) or (word.text in features):\n",
        "                        related_word = word.text if head and head.text in features else head.text if head else None\n",
        "                        feature = head.text if head and head.text in features else word.text\n",
        "                        if related_word:\n",
        "                            opinion_words[related_word] = feature\n",
        "        opinion_words_list.append(opinion_words)\n",
        "    return opinion_words_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UuQYy7qG4Ug"
      },
      "source": [
        "## Sentiment Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJupsAcPCR3b"
      },
      "outputs": [],
      "source": [
        "# def sentiment_score(word):\n",
        "#     synsets = list(swn.senti_synsets(word))\n",
        "#     if not synsets:\n",
        "#         return 0\n",
        "#     score = 0\n",
        "#     for synset in synsets:\n",
        "#         score += synset.pos_score() - synset.neg_score()\n",
        "#     return score / len(synsets)\n",
        "\n",
        "# def aspect_sentiment_scores(opinion_words):\n",
        "#     scores = {}\n",
        "#     for aspect, words in opinion_words.items():\n",
        "#         score = 0\n",
        "#         for word in words:\n",
        "#             score += sentiment_score(word)\n",
        "#         scores[aspect] = score / len(words) if words else 0\n",
        "#     return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d63e6bWfbyN6"
      },
      "outputs": [],
      "source": [
        "def are_related(word1, word2):\n",
        "    synsets1 = wn.synsets(word1)\n",
        "    synsets2 = wn.synsets(word2)\n",
        "    for synset1 in synsets1:\n",
        "        for synset2 in synsets2:\n",
        "            if synset1 == synset2:\n",
        "                return True\n",
        "            if synset2 in synset1.hypernyms() + synset1.hyponyms() + synset1.part_meronyms() + synset1.substance_meronyms() + synset1.member_meronyms():\n",
        "                return True\n",
        "            if synset1 in synset2.hypernyms() + synset2.hyponyms() + synset2.part_meronyms() + synset2.substance_meronyms() + synset2.member_meronyms():\n",
        "                return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdAL6y4-Z0Bh"
      },
      "outputs": [],
      "source": [
        "def sentiment_score(word):\n",
        "    synsets = list(swn.senti_synsets(word))\n",
        "    if not synsets:\n",
        "        return 0\n",
        "    score = 0\n",
        "    for synset in synsets:\n",
        "        score += synset.pos_score() - synset.neg_score()\n",
        "    return score / len(synsets)\n",
        "\n",
        "def aspect_sentiment_scores(opinion_words_list):\n",
        "    aspect_scores = {}\n",
        "    for opinion_words in opinion_words_list:\n",
        "        for word, feature in opinion_words.items():\n",
        "            score = sentiment_score(word)\n",
        "            # Check if the feature is already in the aspect_scores\n",
        "            related_feature = next((f for f in aspect_scores if are_related(f, feature)), None)\n",
        "            if related_feature:\n",
        "                aspect_scores[related_feature] += score\n",
        "            else:\n",
        "                aspect_scores[feature] = score\n",
        "    return aspect_scores\n",
        "\n",
        "# Function to calculate aspect sentiment scores based on the current approach\n",
        "# def aspect_sentiment_scores(opinion_words_list):\n",
        "#     aspect_scores = []\n",
        "#     for opinion_words in opinion_words_list:\n",
        "#         scores = {}\n",
        "#         for word, feature in opinion_words.items():\n",
        "#             score = sentiment_score(word)\n",
        "#             if feature in scores:\n",
        "#                 scores[feature].append(score)\n",
        "#             else:\n",
        "#                 scores[feature] = [score]\n",
        "#         # Calculate average sentiment score for each feature\n",
        "#         avg_scores = {feature: sum(scores[feature]) / len(scores[feature]) for feature in scores}\n",
        "#         aspect_scores.append(avg_scores)\n",
        "#     return aspect_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmVHDSMespVv",
        "outputId": "e1457624-9452-4eed-a0ee-6bb1e79bde79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment scores saved to /content/drive/MyDrive/skripsi_data/Iphone_SE_3_Team_VRY_Scores.csv\n"
          ]
        }
      ],
      "source": [
        "def process_comments(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    comments = df['Comment'].dropna().tolist()\n",
        "    preprocessed_comments = [preprocess_text(comment) for comment in comments if preprocess_text(comment) is not None]\n",
        "    subjective_comments = [remove_objective_sentences(comment) for comment in preprocessed_comments if remove_objective_sentences(comment) != '']\n",
        "    features = extract_features(subjective_comments)\n",
        "    opinion_words = extract_opinion_words(features)\n",
        "    scores = aspect_sentiment_scores(opinion_words)\n",
        "    return scores\n",
        "\n",
        "# Example usage\n",
        "csv_path = '/content/drive/MyDrive/skripsi_data/Iphone SE 3 - Team VRY.csv'\n",
        "scores = process_comments(csv_path)\n",
        "\n",
        "# Convert the scores to a DataFrame and save as CSV\n",
        "output_df = pd.DataFrame(list(scores.items()), columns=['Aspect', 'Sentiment Score'])\n",
        "output_csv_path = '/content/drive/MyDrive/skripsi_data/Iphone_SE_3_Team_VRY_Scores.csv'\n",
        "output_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"Sentiment scores saved to {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz42tXwNA1EG"
      },
      "source": [
        "## Get all of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlXL_Zpg-JK0"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "comments = [\n",
        "    \"This phone is sooooo guuuuddd! 😃\",\n",
        "    \"10:30 The battery life is amazing!\",\n",
        "    \"Ich liebe dieses Telefon!\",\n",
        "    \"12:45 The screen is very clear and bright.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDLK6_DYA7ct",
        "outputId": "61aca5ff-b1b9-43ed-99ff-dbc68828595c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ich liebe dieses Telefon!  is not english\n",
            "Preprocessed comments: ['his phone is sooooo guuuuddd!', 'the battery life is amazing!', 'the screen is very clear and bright.']\n"
          ]
        }
      ],
      "source": [
        "preprocessed_comments = [preprocess_text(comment) for comment in comments if preprocess_text(comment) is not None]\n",
        "print(\"Preprocessed comments:\", preprocessed_comments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyycXyKKBHdm",
        "outputId": "5c35b6a7-cf8b-47b3-da51-a21e3c63c079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['his phone is sooooo guuuuddd!', 'the battery life is amazing!', 'the screen is very clear and bright.']\n"
          ]
        }
      ],
      "source": [
        "# Remove objective sentences and process further\n",
        "all_filtered_sentences = []\n",
        "for comment in preprocessed_comments:\n",
        "    filtered_sentences = remove_objective_sentences(comment)\n",
        "    all_filtered_sentences.extend(filtered_sentences)\n",
        "print(all_filtered_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ9pNAEvBObY",
        "outputId": "d9999f0a-df54-47b6-9883-8188c44cefe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'his phone is sooooo guuuuddd!': ['phone', 'guuuuddd'], 'the battery life is amazing!': ['battery', 'life'], 'the screen is very clear and bright.': ['screen']}\n"
          ]
        }
      ],
      "source": [
        "# Extract features from the filtered sentences\n",
        "features = extract_features(all_filtered_sentences)\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VmX8oEqSIby",
        "outputId": "f54983ef-9486-4a48-a28a-3d45a6855408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: The\tHead: screen\tDep: det\n",
            "Word: screen\tHead: clear\tDep: nsubj\n",
            "Word: is\tHead: clear\tDep: cop\n",
            "Word: very\tHead: clear\tDep: advmod\n",
            "Word: clear\tHead: root\tDep: root\n",
            "Word: and\tHead: bright\tDep: cc\n",
            "Word: bright\tHead: clear\tDep: conj\n",
            "Word: .\tHead: clear\tDep: punct\n"
          ]
        }
      ],
      "source": [
        "text = \"The screen is very clear and bright.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract dependencies\n",
        "for sentence in doc.sentences:\n",
        "    for word in sentence.words:\n",
        "        print(f'Word: {word.text}\\tHead: {sentence.words[word.head - 1].text if word.head > 0 else \"root\"}\\tDep: {word.deprel}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gHeXGiBBROk",
        "outputId": "d5eca7b6-b82f-4467-c7ac-35a0079f5213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'phone': 'guuuuddd', 'sooooo': 'guuuuddd'}, {'amazing': 'life'}, {'clear': 'screen'}]\n"
          ]
        }
      ],
      "source": [
        "# Extract opinion words related to the features\n",
        "opinion_words = extract_opinion_words(features)\n",
        "print(opinion_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae--5GTGZ9te",
        "outputId": "4a8f3669-f632-4f3d-db00-ec17bbc143e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aspect sentiment scores: {'guuuuddd': 0, 'life': 0.15625, 'screen': 0.16666666666666666}\n"
          ]
        }
      ],
      "source": [
        "aspect_scores = aspect_sentiment_scores(opinion_words)\n",
        "print(\"Aspect sentiment scores:\", aspect_scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "2tdWhOt575vG",
        "dQ-LTgQatXIi",
        "sQeo2iTwDROo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ea0faf00c4f49a18a58909bbde9f033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12c1d9fc7a67443db1363885e59d925b",
            "placeholder": "​",
            "style": "IPY_MODEL_b849f91d9d114ff0a946835eb65b46bb",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
          }
        },
        "12c1d9fc7a67443db1363885e59d925b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18bc662c73cc496d8134115d8c665b40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bbde817185649b8bed1ed1b2d06f416": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e38d66b65d747b096fc220ed3dc183d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18bc662c73cc496d8134115d8c665b40",
            "placeholder": "​",
            "style": "IPY_MODEL_675579a2a7f84d1c9b50554d80ba9bfd",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/default.zip: 100%"
          }
        },
        "25c41c90875542e5a371964bc8afb4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27380f26e19a4dfc80ef49884ceb6be1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a051626c39740ec84c46d6162120c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ea0faf00c4f49a18a58909bbde9f033",
              "IPY_MODEL_4f5ce3f29b1a469eae4547fe647c5779",
              "IPY_MODEL_d2b13dc27e7d40cd90098aedf12fb0b5"
            ],
            "layout": "IPY_MODEL_25c41c90875542e5a371964bc8afb4f1"
          }
        },
        "4f5ce3f29b1a469eae4547fe647c5779": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e168bbb9b6e481a8170a5755e620267",
            "max": 47208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c022bef93aa2489babc0b598695cf250",
            "value": 47208
          }
        },
        "594f1bdecb4b44a2989173808be18edb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6675d1a0e2b641519842de6f0048f7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675579a2a7f84d1c9b50554d80ba9bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e168bbb9b6e481a8170a5755e620267": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713e87e5fb0647b6b8c3af837200ad68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7780c707c71949b58329d5246e659943": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf519aad79e84cb69dd8bd891e9a1dad",
            "max": 47208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bbde817185649b8bed1ed1b2d06f416",
            "value": 47208
          }
        },
        "7d1bd2a1f6894fd2b22873070e2e57a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8007b88fb6e04aa5b576bb7708d8f772": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27380f26e19a4dfc80ef49884ceb6be1",
            "max": 526684143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_713e87e5fb0647b6b8c3af837200ad68",
            "value": 526684143
          }
        },
        "81729b660cc148aea81b5d29a9a15f5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a3522034d24241aada652f76b64f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6332d64ca7d4ade91b5736a608ad58e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b220ad4c995d4fcab809e7205182741c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d78053a1b9ac4dfc9ced4c1b6534e35b",
              "IPY_MODEL_7780c707c71949b58329d5246e659943",
              "IPY_MODEL_e3ef2d45d8be47dc991df0fd6d46e8ad"
            ],
            "layout": "IPY_MODEL_fd414f991fca4b8dade68e4cf7bd0873"
          }
        },
        "b7de5ec64d2c4fbabf0a6dfd72374308": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b849f91d9d114ff0a946835eb65b46bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c022bef93aa2489babc0b598695cf250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce925bb0ff354ea49a83977cabc8dad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e38d66b65d747b096fc220ed3dc183d",
              "IPY_MODEL_8007b88fb6e04aa5b576bb7708d8f772",
              "IPY_MODEL_fa2d09abd60c45ceadf6b9bfe03f54ee"
            ],
            "layout": "IPY_MODEL_b7de5ec64d2c4fbabf0a6dfd72374308"
          }
        },
        "cf519aad79e84cb69dd8bd891e9a1dad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2b13dc27e7d40cd90098aedf12fb0b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_594f1bdecb4b44a2989173808be18edb",
            "placeholder": "​",
            "style": "IPY_MODEL_6675d1a0e2b641519842de6f0048f7e7",
            "value": " 379k/? [00:00&lt;00:00, 7.20MB/s]"
          }
        },
        "d7713d5bc17545b5aea811148fcfda08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78053a1b9ac4dfc9ced4c1b6534e35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7713d5bc17545b5aea811148fcfda08",
            "placeholder": "​",
            "style": "IPY_MODEL_ef8eb460a4f04ee1b3f9ed14cc32fdcb",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "
          }
        },
        "e3ef2d45d8be47dc991df0fd6d46e8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81729b660cc148aea81b5d29a9a15f5a",
            "placeholder": "​",
            "style": "IPY_MODEL_7d1bd2a1f6894fd2b22873070e2e57a4",
            "value": " 379k/? [00:00&lt;00:00, 8.01MB/s]"
          }
        },
        "ef8eb460a4f04ee1b3f9ed14cc32fdcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa2d09abd60c45ceadf6b9bfe03f54ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6332d64ca7d4ade91b5736a608ad58e",
            "placeholder": "​",
            "style": "IPY_MODEL_97a3522034d24241aada652f76b64f16",
            "value": " 527M/527M [00:16&lt;00:00, 37.8MB/s]"
          }
        },
        "fd414f991fca4b8dade68e4cf7bd0873": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
